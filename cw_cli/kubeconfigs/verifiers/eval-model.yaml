apiVersion: batch/v1
kind: Job
metadata:
  name: cw-verifiers-eval-grpo # Consider generateName for multiple runs: cw-verifiers-training-job-
  labels:
    app: verifiers-eval
    task: evaluation # Task label for anti-affinity
spec:
  ttlSecondsAfterFinished: 0              # ‚Üê delete Job immediately after it finishes
  backoffLimit: 0   
  template:
    metadata:
      labels:
        app: verifiers-eval # Pods get this label
        task: training     # And this task label
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: task # Avoid pods with these task labels
                operator: In
                values:
                - serving
                - rewards
            topologyKey: "kubernetes.io/hostname"
      initContainers:
      - name: wait-for-vllm
        image: busybox:1.28 # Or any small image with nc/curl
        command: ['sh', '-c', 'until nc -zv cw-verifiers-vllm-service 8000; do echo "Waiting for VLLM service..."; sleep 5; done']
      - name: wait-for-rewards
        image: busybox:1.28 # Or any small image with nc/curl
        command: ['sh', '-c', 'until nc -zv cw-verifiers-rewards-service-grpo 9347; do echo "Waiting for rewards service..."; sleep 5; done']
      # imagePullSecrets: ...
      containers:
      - name: verifiers-train-container
        image: ghcr.io/tcapelle/triton_eval:1906 # <-- UPDATE THIS
        workingDir: /app/
        command: ["sh"]
        args:
          - "-c"
          - |
            # Pull latest if requested
            if [ "${PULL_LATEST:-false}" = "true" ]; then
              echo "üîÑ Pulling latest `triton_eval` code..."
              cd /app/ && git pull origin main
              echo "‚úÖ Code updated successfully"
            fi
            
            # verifiers
            pip install git+https://github.com/tcapelle/verifiers.git@weave

            # train
            python eval_with_weave_n.py --num_generations NUM_GENERATIONS \
             --model_name MODEL_NAME \
             --dataset_name DATASET_NAME \
             --custom_base_url http://cw-verifiers-vllm-service:8000/v1 \
             --triton_server_url http://cw-verifiers-rewards-service-grpo:9347

        env:
        - name: WANDB_API_KEY
          valueFrom:
            secretKeyRef:
              name: wandb-api-key-secret # Name of the secret you created
              key: WANDB_API_KEY        # Key within the secret
        - name: WEAVE_PRINT_CALL_LINK
          value: "0"
        - name: TOKENIZERS_PARALLELISM
          value: "0"
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-token-secret # Name of the secret for HF_TOKEN
              key: HF_TOKEN        # Key within the hf-token-secret
        # You can add other environment variables here if needed
        # - name: ANOTHER_ENV_VAR
        #   value: "some_value"
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - name: config-volume
            mountPath: /mnt/verifiers-config
          - mountPath: /model-checkpoints
            name: model-checkpoints
        resources:
          limits:
            nvidia.com/gpu: 
            cpu: "32"
            memory: "2000Gi"
          requests:
            cpu: "8"
            memory: "64Gi"
            nvidia.com/gpu: 
      volumes:
        - name: model-checkpoints
          persistentVolumeClaim:
            claimName: model-checkpoints
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 200Gi # Adjust size as needed
        - name: config-volume
          configMap:
            name: cw-verifiers-eval-config
      restartPolicy: OnFailure
      # tolerations: ...
      # nodeSelector: ...
  backoffLimit: 0 # No retries for the job on failure 